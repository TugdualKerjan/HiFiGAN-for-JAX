{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Implementing a HiFiGAN in JAX for fun üòé\"\n",
    "author:\n",
    "  - name: \"Tugdual Kerjan\"\n",
    "    url: https://tugdual.fr\n",
    "    email: tkerjan@outlook.com\n",
    "date: \"November 7, 2024\"\n",
    "number-sections: true\n",
    "reference-location: margin\n",
    "toc: true\n",
    "format: \n",
    "  html:\n",
    "    standalone: true\n",
    "    embed-resources: true\n",
    "    self-contained-math: true\n",
    "    code-fold: false\n",
    "    code-tools: true\n",
    "execute:\n",
    "  output:\n",
    "    false\n",
    "bibliography: assets/bib.bibtex\n",
    "theme: united\n",
    "github: \"https://github.com/TugdualKerjan/HiFiGAN-for-JAX\"\n",
    "lightbox: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full project, visit the [GitHub repository](https://github.com/TugdualKerjan/HiFiGAN-for-JAX).\n",
    "\n",
    "# Context üëÄ\n",
    "\n",
    "I'm trying to rewrite XTTS in JAX to understand how it works. \n",
    "\n",
    "We are going to implement the HiFiGAN used in [@casanova2024xttsmassivelymultilingualzeroshot], a Text to Speech model written by the defunct Coqai company. The HiFiGAN model was first proposed in [@kong2020hifigangenerativeadversarialnetworks]. The role of this model is to take Mel Spectrograms that represent a sequence of speech and transform them into a wav that we can listen to. This is what comes at the end of the XTTS model that will generate the spectrograms feeding the model. HiFiGaN is composed of a generator and two discriminators.\n",
    "\n",
    "__Generator__\n",
    "\n",
    "This part of the model takes in the Mel-Spectrogram and iteratively convolves the input into the desired output shape, here a $[1 \\times N]$ tensor representing the time-series (a list of points) giving the amplitude of the sound. Passing this with a sampling rate to audio programs would allow us to listen to it !\n",
    "\n",
    "__Discriminators__\n",
    "\n",
    "Since we want the output to be as real as possible, we can use _other_ models to learn to learn to discern the output of our generator from other real inputs. Basically, if this model can't see the difference between real or fake audio then either our generator is doing a good job or the discriminator is doing a bad one !\n",
    "\n",
    "Here the paper proposes two: One that looks at spaced out points to find patterns that could help discern real from fake, and one that looks at different scales. We can think of this second one as an inspector looking at a modified image for artifacts in hair, or on a bigger scale how the eyes are placed relative to the face. _Anyways_.\n",
    "\n",
    "![What we hope happens](assets/dis.png)\n",
    "\n",
    "# Goal üéØ\n",
    "\n",
    "Get intelligable speech coming out of the HiFiGAN with reasonable (1h tops) amount of training on a NVIDIA L40.\n",
    "\n",
    "Since our final goal is to recreate a 1 to 1 version of the VQVAE used in XTTS, we'll hardcode a lot of things to minimize issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (50194444.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    (conv_pre): ParametrizedConv1d(\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "HifiganGenerator(\n",
    "  (conv_pre): ParametrizedConv1d(\n",
    "    80, 512, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "    (parametrizations): ModuleDict(\n",
    "      (weight): ParametrizationList(\n",
    "        (0): _WeightNorm()\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "  (ups): ModuleList(\n",
    "    (0): ParametrizedConvTranspose1d(\n",
    "      512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
    "      (parametrizations): ModuleDict(\n",
    "        (weight): ParametrizationList(\n",
    "          (0): _WeightNorm()\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (1): ParametrizedConvTranspose1d(\n",
    "      256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
    "      (parametrizations): ModuleDict(\n",
    "        (weight): ParametrizationList(\n",
    "          (0): _WeightNorm()\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (2): ParametrizedConvTranspose1d(\n",
    "      128, 64, kernel_size=(4,), stride=(4,)\n",
    "      (parametrizations): ModuleDict(\n",
    "        (weight): ParametrizationList(\n",
    "          (0): _WeightNorm()\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (3): ParametrizedConvTranspose1d(\n",
    "      64, 32, kernel_size=(4,), stride=(4,)\n",
    "      (parametrizations): ModuleDict(\n",
    "        (weight): ParametrizationList(\n",
    "          (0): _WeightNorm()\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "  (resblocks): ModuleList(\n",
    "    (0): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (1): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0): ParametrizedConv1d(\n",
    "          256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (1): ParametrizedConv1d(\n",
    "          256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (2): ParametrizedConv1d(\n",
    "          256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (2): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (3): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0): ParametrizedConv1d(\n",
    "          128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (1): ParametrizedConv1d(\n",
    "          128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (2): ParametrizedConv1d(\n",
    "          128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (4): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (5): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0): ParametrizedConv1d(\n",
    "          64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (1): ParametrizedConv1d(\n",
    "          64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (2): ParametrizedConv1d(\n",
    "          64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (6): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (7): ResBlock1(\n",
    "      (convs1): ModuleList(\n",
    "        (0): ParametrizedConv1d(\n",
    "          32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (1): ParametrizedConv1d(\n",
    "          32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        (2): ParametrizedConv1d(\n",
    "          32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (convs2): ModuleList(\n",
    "        (0-2): 3 x ParametrizedConv1d(\n",
    "          32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "          (parametrizations): ModuleDict(\n",
    "            (weight): ParametrizationList(\n",
    "              (0): _WeightNorm()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "  (conv_post): ParametrizedConv1d(\n",
    "    32, 1, kernel_size=(7,), stride=(1,), padding=(3,)\n",
    "    (parametrizations): ModuleDict(\n",
    "      (weight): ParametrizationList(\n",
    "        (0): _WeightNorm()\n",
    "      )\n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We have 3 models to code: Generator, MultiPeriod Discriminator and the MultiScaleDiscriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing JAX and Equinox, a library that helps with writing neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import equinox.nn as nn\n",
    "import typing as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResBlocks\n",
    "\n",
    "Two types of ResBlocks are proposed in the HiFiGAN paper, but only one is implemented in XTTS, as we can see below:\n",
    "\n",
    "![ResBlocks later used in the generator [@kong2020hifigangenerativeadversarialnetworks]](assets/resblocks.png)\n",
    "\n",
    "We implement them below following XTTS's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "LRELU_SLOPE = 0.1\n",
    "\n",
    "\n",
    "class ResBlock(eqx.Module):\n",
    "    conv_dil: list\n",
    "    conv_straight: list\n",
    "    norm = nn.WeightNorm\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        dilation: list = [1, 3, 5],\n",
    "        key=None,\n",
    "    ):\n",
    "        if key is None:\n",
    "            raise ValueError(\"The 'key' parameter cannot be None.\")\n",
    "        self.conv_dil = [\n",
    "            nn.Conv1d(\n",
    "                channels,\n",
    "                channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                dilation=x,\n",
    "                padding=\"SAME\",\n",
    "                key=y,\n",
    "            )\n",
    "            for x, y in zip(dilation, jax.random.split(key, 3))\n",
    "        ]\n",
    "        self.conv_straight = [\n",
    "            nn.Conv1d(\n",
    "                channels,\n",
    "                channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                dilation=1,\n",
    "                padding=\"SAME\",\n",
    "                key=y,\n",
    "            )\n",
    "            for _, y in zip(dilation, jax.random.split(key, 3))\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for c1, c2 in zip(self.conv_dil, self.conv_straight):\n",
    "\n",
    "            y = jax.nn.leaky_relu(x, LRELU_SLOPE)\n",
    "            y = self.norm(c1)(y)\n",
    "            y = jax.nn.leaky_relu(y, LRELU_SLOPE)\n",
    "            y = self.norm(c2)(y)\n",
    "            x = y + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run some simple test to see if it's at least spiting out the right shape and working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0058002337\n",
      "0.0058002337\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros_like requires ndarray or scalar arguments, got <class 'functools.partial'> at position 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madam(\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39minit(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/optax/transforms/_combining.py:64\u001b[0m, in \u001b[0;36mchain.<locals>.init_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(params):\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(fn(params) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m init_fns)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/optax/transforms/_combining.py:64\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(params):\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(fn(params) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m init_fns)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/optax/_src/transform.py:215\u001b[0m, in \u001b[0;36mscale_by_adam.<locals>.init_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(params):\n\u001b[0;32m--> 215\u001b[0m     mu \u001b[38;5;241m=\u001b[39m otu\u001b[38;5;241m.\u001b[39mtree_zeros_like(params, dtype\u001b[38;5;241m=\u001b[39mmu_dtype)  \u001b[38;5;66;03m# First moment\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     nu \u001b[38;5;241m=\u001b[39m otu\u001b[38;5;241m.\u001b[39mtree_zeros_like(params)  \u001b[38;5;66;03m# Second moment\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ScaleByAdamState(count\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mzeros([], jnp\u001b[38;5;241m.\u001b[39mint32), mu\u001b[38;5;241m=\u001b[39mmu, nu\u001b[38;5;241m=\u001b[39mnu)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/optax/tree_utils/_tree_math.py:219\u001b[0m, in \u001b[0;36mtree_zeros_like\u001b[0;34m(tree, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_zeros_like\u001b[39m(\n\u001b[1;32m    207\u001b[0m     tree: Any,\n\u001b[1;32m    208\u001b[0m     dtype: Optional[jax\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates an all-zeros tree with the same structure.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    an all-zeros tree with the same structure as ``tree``.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jtu\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp\u001b[38;5;241m.\u001b[39mzeros_like(x, dtype\u001b[38;5;241m=\u001b[39mdtype), tree)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/tree_util.py:344\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    342\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    343\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/tree_util.py:344\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    343\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/optax/tree_utils/_tree_math.py:219\u001b[0m, in \u001b[0;36mtree_zeros_like.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_zeros_like\u001b[39m(\n\u001b[1;32m    207\u001b[0m     tree: Any,\n\u001b[1;32m    208\u001b[0m     dtype: Optional[jax\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates an all-zeros tree with the same structure.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    an all-zeros tree with the same structure as ``tree``.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jtu\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp\u001b[38;5;241m.\u001b[39mzeros_like(x, dtype\u001b[38;5;241m=\u001b[39mdtype), tree)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:5678\u001b[0m, in \u001b[0;36mzeros_like\u001b[0;34m(a, dtype, shape, device)\u001b[0m\n\u001b[1;32m   5647\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an array full of zeros with the same shape and dtype as an array.\u001b[39;00m\n\u001b[1;32m   5648\u001b[0m \n\u001b[1;32m   5649\u001b[0m \u001b[38;5;124;03mJAX implementation of :func:`numpy.zeros_like`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5675\u001b[0m \u001b[38;5;124;03m         [0, 0, 0]], dtype=int32)\u001b[39;00m\n\u001b[1;32m   5676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m)):  \u001b[38;5;66;03m# support duck typing\u001b[39;00m\n\u001b[0;32m-> 5678\u001b[0m   util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros_like\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[1;32m   5679\u001b[0m dtypes\u001b[38;5;241m.\u001b[39mcheck_user_dtype_supported(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros_like\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/numpy/util.py:316\u001b[0m, in \u001b[0;36mcheck_arraylike\u001b[0;34m(fun_name, emit_warning, stacklevel, *args)\u001b[0m\n\u001b[1;32m    313\u001b[0m   warnings\u001b[38;5;241m.\u001b[39mwarn(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m In a future JAX release this will be an error.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m                 category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(fun_name, \u001b[38;5;28mtype\u001b[39m(arg), pos))\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros_like requires ndarray or scalar arguments, got <class 'functools.partial'> at position 0."
     ]
    }
   ],
   "source": [
    "# | code-fold: true\n",
    "\n",
    "key = jax.random.PRNGKey(4)\n",
    "key1, key2 = jax.random.split(key)\n",
    "\n",
    "model = ResBlock(100, key=key1)\n",
    "x = jax.random.normal(key2, shape=(10, 100, 69))\n",
    "x = jax.vmap(model)(x)\n",
    "print(jnp.mean(x))\n",
    "print(jnp.mean(x))\n",
    "\n",
    "import optax\n",
    "\n",
    "optimizer = optax.adam(1e-5)\n",
    "opt_state = optimizer.init(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move onto implementing the rest of the Generator, which basically just uses a _bunch_ of different ResBlocks at varying kernel sizes and strides to capture as much information to then transform slowly into a waveform (i.e. an array of points with a sampling rate).\n",
    "\n",
    "![A bigger view of the generator, layers of Resblocks basically. [@kong2020hifigangenerativeadversarialnetworks]](assets/generator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRF(eqx.Module):\n",
    "    resblocks: list\n",
    "\n",
    "    def __init__(self, channel_in: int, kernel_sizes: list, dilations: list, key=None):\n",
    "        if key is None:\n",
    "            raise ValueError(\"The 'key' parameter cannot be None.\")\n",
    "        self.resblocks = [\n",
    "            ResBlock(channel_in, kernel_size, dilation, key=y)\n",
    "            for kernel_size, dilation, y in zip(\n",
    "                kernel_sizes, dilations, jax.random.split(key, len(kernel_sizes))\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = self.resblocks[0](x)\n",
    "        for block in self.resblocks[1:]:\n",
    "            y += block(x)\n",
    "\n",
    "        return y / len(self.resblocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create each \"MRF\" i.e. list of ResBlocks and call it the Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(eqx.Module):\n",
    "    conv_pre: nn.Conv1d\n",
    "\n",
    "    layers: list\n",
    "\n",
    "    post_magic: nn.Conv1d\n",
    "\n",
    "    norm = nn.WeightNorm\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in: int,\n",
    "        channels_out: int,\n",
    "        h_u=512,\n",
    "        k_u=[16, 16, 4, 4],\n",
    "        upsample_rate_decoder=[8, 8, 2, 2],\n",
    "        k_r=[3, 7, 11],\n",
    "        dilations=[[1, 1], [3, 1], [5, 1]],\n",
    "        key=None,\n",
    "    ):\n",
    "\n",
    "        if key is None:\n",
    "            raise ValueError(\"The 'key' parameter cannot be None.\")\n",
    "        key, grab = jax.random.split(key, 2)\n",
    "        self.conv_pre = nn.Conv1d(\n",
    "            channels_in, h_u, kernel_size=7, dilation=1, padding=3, key=grab\n",
    "        )\n",
    "\n",
    "        # This is where the magic happens. Upsample aggressively then more slowly. TODO could play around with this.\n",
    "        # Then convolve one last time (Curious to see the weights to see if has good impact)\n",
    "        self.layers = [\n",
    "            (\n",
    "                nn.ConvTranspose1d(\n",
    "                    int(h_u / (2**i)),\n",
    "                    int(h_u / (2 ** (i + 1))),\n",
    "                    kernel_size=k,\n",
    "                    stride=u,\n",
    "                    padding=\"SAME\",\n",
    "                    key=y,\n",
    "                ),\n",
    "                MRF(\n",
    "                    channel_in=int(h_u / (2 ** (i + 1))),\n",
    "                    kernel_sizes=k_r,\n",
    "                    dilations=dilations,\n",
    "                    key=y,\n",
    "                ),\n",
    "            )\n",
    "            for i, (k, u, y) in enumerate(\n",
    "                zip(k_u, upsample_rate_decoder, jax.random.split(key, len(k_u)))\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.post_magic = nn.Conv1d(\n",
    "            int(h_u / (2 ** len(k_u))),\n",
    "            channels_out,\n",
    "            kernel_size=7,\n",
    "            stride=1,\n",
    "            padding=3,\n",
    "            key=key,\n",
    "        )\n",
    "        # self.post_magic = nn.WeightNorm(self.post_magic,\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        y = self.norm(self.conv_pre)(x)\n",
    "\n",
    "        for upsample, mrf in self.layers:\n",
    "            y = jax.nn.leaky_relu(y, LRELU_SLOPE)\n",
    "            y = self.norm(upsample)(y)  # Upsample\n",
    "            y = mrf(y)\n",
    "\n",
    "        y = jax.nn.leaky_relu(y, LRELU_SLOPE)\n",
    "        y = self.norm(self.post_magic)(y)\n",
    "        y = jax.nn.tanh(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòÆ‚Äçüí® Ok that was FAT ! We now should have a model that can take in images like mel spectrograms and transform them into waves. Let's quickly check it's at least outputting the right dimensions given an input. Based on our `upsample_rate_decoder` any mel spectrogram of the form $[Melbins \\times length]$ becomes $[1 \\times length \\cdot 256] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09683815\n",
      "0.09683815\n",
      "(1, 1, 262144)\n"
     ]
    }
   ],
   "source": [
    "# | code-fold: true\n",
    "\n",
    "key = jax.random.PRNGKey(4)\n",
    "key1, key2 = jax.random.split(key)\n",
    "\n",
    "model = Generator(80, 1, key=key1)\n",
    "x = jax.random.normal(key2, shape=(1, 80, 1024))\n",
    "x = jax.vmap(model)(x)\n",
    "\n",
    "\n",
    "import optax\n",
    "\n",
    "optimizer = optax.adam(1e-5)\n",
    "opt_state = optimizer.init(model)\n",
    "\n",
    "print(jnp.mean(x))\n",
    "print(jnp.mean(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminators\n",
    "\n",
    "We can now move onto writing up the discriminators that will attempt to discern fake from real outputs.\n",
    "\n",
    "![The two discriminators used by XTTS and mentionned in the OG paper [@kong2020hifigangenerativeadversarialnetworks]](assets/discriminators.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start by writing the Periodic Discriminator. Both discriminators are actually a set of models with varying input sizes. The code below is mainly a rewrite from the code available here: [@hifiganimplementationgithub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "class DiscriminatorP(eqx.Module):\n",
    "    layers: list\n",
    "    period: int\n",
    "    conv_post: nn.Conv2d\n",
    "    norm = nn.WeightNorm\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        period: int,\n",
    "        kernel_size=5,\n",
    "        stride=3,\n",
    "        key: jax.Array = jax.random.PRNGKey(0),\n",
    "    ):\n",
    "        self.period = period\n",
    "\n",
    "        keys = jax.random.split(key, 6)\n",
    "        self.layers = [\n",
    "            nn.Conv2d(\n",
    "                1,\n",
    "                32,\n",
    "                (kernel_size, 1),\n",
    "                (stride, 1),\n",
    "                padding=\"SAME\",\n",
    "                key=keys[0],\n",
    "            ),\n",
    "            nn.Conv2d(\n",
    "                32,\n",
    "                128,\n",
    "                (kernel_size, 1),\n",
    "                (stride, 1),\n",
    "                padding=\"SAME\",\n",
    "                key=keys[1],\n",
    "            ),\n",
    "            nn.Conv2d(\n",
    "                128,\n",
    "                512,\n",
    "                (kernel_size, 1),\n",
    "                (stride, 1),\n",
    "                padding=\"SAME\",\n",
    "                key=keys[2],\n",
    "            ),\n",
    "            nn.Conv2d(\n",
    "                512,\n",
    "                1024,\n",
    "                (kernel_size, 1),\n",
    "                (stride, 1),\n",
    "                padding=\"SAME\",\n",
    "                key=keys[3],\n",
    "            ),\n",
    "            nn.Conv2d(1024, 1024, (kernel_size, 1), 1, padding=\"SAME\", key=keys[4]),\n",
    "        ]\n",
    "        self.conv_post = nn.Conv2d(1024, 1, (3, 1), 1, padding=\"SAME\", key=keys[5])\n",
    "\n",
    "    def pad_and_reshape(self, x):\n",
    "        c, t = x.shape\n",
    "        n_pad = (self.period - (t % self.period)) % self.period\n",
    "        x_padded = jnp.pad(x, ((0, 0), (0, n_pad)), mode=\"reflect\")\n",
    "        t_new = x_padded.shape[-1] // self.period\n",
    "        return x_padded.reshape(c, t_new, self.period)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Feature map for loss\n",
    "        fmap = []\n",
    "\n",
    "        x = self.pad_and_reshape(x)\n",
    "        for layer in self.layers:\n",
    "            x = self.norm(layer)(x)\n",
    "            x = jax.nn.leaky_relu(x, LRELU_SLOPE)\n",
    "            fmap.append(x)\n",
    "        x = self.norm(self.conv_post)(x)\n",
    "        fmap.append(x)\n",
    "        x = jnp.reshape(x, shape=(1, -1))\n",
    "        return x, fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're also returning the activations of each intermediate layer. This is because we'll implement a loss that doesn't just compare the output but the intermediate outputs between real and fake inputs. We can now define the discriminator that looks at different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorS(eqx.Module):\n",
    "    layers: list\n",
    "    conv_post: nn.Conv1d\n",
    "    norm = nn.WeightNorm\n",
    "\n",
    "    def __init__(self, key: jax.Array = jax.random.PRNGKey(0)):\n",
    "        key1, key2, key3, key4, key5, key6, key7, key8 = jax.random.split(key, 8)\n",
    "\n",
    "        self.layers = [\n",
    "            nn.Conv1d(1, 128, 15, 1, padding=7, key=key1),\n",
    "            nn.Conv1d(128, 128, 41, 2, groups=4, padding=20, key=key2),\n",
    "            nn.Conv1d(128, 256, 41, 2, groups=16, padding=20, key=key3),\n",
    "            nn.Conv1d(256, 512, 41, 4, groups=16, padding=20, key=key4),\n",
    "            nn.Conv1d(512, 1024, 41, 4, groups=16, padding=20, key=key5),\n",
    "            nn.Conv1d(1024, 1024, 41, 1, groups=16, padding=20, key=key),\n",
    "            nn.Conv1d(1024, 1024, 5, 1, padding=2, key=key7),\n",
    "        ]\n",
    "        self.conv_post = nn.Conv1d(1024, 1, 3, 1, padding=1, key=key8)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Feature map for loss\n",
    "        fmap = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = self.norm(layer)(x)\n",
    "            x = jax.nn.leaky_relu(x, LRELU_SLOPE)\n",
    "            fmap.append(x)\n",
    "\n",
    "        x = self.norm(self.conv_post)(x)\n",
    "        fmap.append(x)\n",
    "        x = jax.numpy.reshape(x, shape=(1, -1))\n",
    "\n",
    "        return x, fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define wrappers for both that will contain various periods or scales. Notice that the periods have prime numbers to avoid overlapping as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleDiscriminator(eqx.Module):\n",
    "    discriminators: list\n",
    "    meanpool: nn.AvgPool1d = nn.AvgPool1d(4, 2, padding=2)\n",
    "\n",
    "    # TODO need to add spectral norm things\n",
    "    def __init__(self, key: jax.Array = jax.random.PRNGKey(0)):\n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "        self.discriminators = [\n",
    "            DiscriminatorS(key1),\n",
    "            DiscriminatorS(key2),\n",
    "            DiscriminatorS(key3),\n",
    "        ]\n",
    "        # self.meanpool = nn.AvgPool1d(4, 2, padding=2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        preds = []\n",
    "        fmaps = []\n",
    "\n",
    "        for disc in self.discriminators:\n",
    "\n",
    "            pred, fmap = disc(x)\n",
    "            preds.append(pred)\n",
    "            fmaps.append(fmap)\n",
    "            x = self.meanpool(x)  # Subtle way of scaling things down by 2\n",
    "\n",
    "        return preds, fmaps\n",
    "\n",
    "\n",
    "class MultiPeriodDiscriminator(eqx.Module):\n",
    "    discriminators: list\n",
    "\n",
    "    def __init__(\n",
    "        self, periods=[2, 3, 5, 7, 11], key: jax.Array = jax.random.PRNGKey(0)\n",
    "    ):\n",
    "        self.discriminators = [\n",
    "            DiscriminatorP(period, key=y)\n",
    "            for period, y in zip(periods, jax.random.split(key, len(periods)))\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        preds = []\n",
    "        fmaps = []\n",
    "\n",
    "        for disc in self.discriminators:\n",
    "            pred, fmap = disc(x)\n",
    "            preds.append(pred)\n",
    "            fmaps.append(fmap)\n",
    "\n",
    "        return preds, fmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations üéâ We've now implemented a HiFiGAN ! Now \"all\" ü§è that remains to do is training it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and gradients\n",
    "\n",
    "We're going to have multiple losses to deal with - a total of 3 actually. The first is the MSE, comparing what our generator produces compared to the ideal output. The next two will be the discriminators. Finally, we need to also define losses for the discriminators, which in our case are simply MSE between real and 1, and fake and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad\n",
    "def calculate_gan_loss(gan, period, scale, x, y):\n",
    "\n",
    "    gan_result = jax.vmap(gan)(x)[:, :, : 22050 * 2]\n",
    "    print(gan_result.shape)\n",
    "    fake_scale, _ = jax.vmap(scale)(gan_result)\n",
    "    fake_period, _ = jax.vmap(period)(gan_result)\n",
    "\n",
    "    l1_loss = jax.numpy.mean(jax.numpy.abs(gan_result - y))  # L1 loss\n",
    "    G_loss = 0\n",
    "    for fake in fake_period:\n",
    "        G_loss += jax.numpy.mean((fake - 1) ** 2)\n",
    "    for fake in fake_scale:\n",
    "        G_loss += jax.numpy.mean((fake - 1) ** 2)\n",
    "    # G_loss_scale = jax.numpy.mean((fake_scale - jax.numpy.ones(batch_size)) ** 2)\n",
    "\n",
    "    return G_loss + 30 * l1_loss\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad\n",
    "def calculate_disc_loss(model, fake, real):\n",
    "    fake_result, _ = jax.vmap(model)(fake)\n",
    "    real_result, _ = jax.vmap(model)(real)\n",
    "    loss = 0\n",
    "    for fake_res, real_res in zip(fake_result, real_result):\n",
    "        fake_loss = jax.numpy.mean((fake_res) ** 2)\n",
    "        real_loss = jax.numpy.mean((real_res - 1) ** 2)\n",
    "        loss += fake_loss + real_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(\n",
    "    gan,\n",
    "    period_disc,\n",
    "    scale_disc,\n",
    "    x,\n",
    "    y,\n",
    "    gan_optim,\n",
    "    period_optim,\n",
    "    scale_optim,\n",
    "    optim1,\n",
    "    optim2,\n",
    "    optim3,\n",
    "):\n",
    "\n",
    "    result = jax.vmap(gan)(x)[:, : 22050 * 2]\n",
    "\n",
    "    # trainable_scale, _ = eqx.partition(scale_disc, eqx.is_inexact_array)\n",
    "    # trainable_period, _ = eqx.partition(period_disc, eqx.is_inexact_array)\n",
    "\n",
    "    loss_scale, grads_scale = calculate_disc_loss(scale_disc, result, y)\n",
    "    updates, scale_optim = optim2.update(grads_scale, scale_optim, scale_disc)\n",
    "    scale_disc = eqx.apply_updates(scale_disc, updates)\n",
    "\n",
    "    loss_period, grads_period = calculate_disc_loss(period_disc, result, y)\n",
    "    updates, period_optim = optim3.update(grads_period, period_optim, period_disc)\n",
    "    period_disc = eqx.apply_updates(period_disc, updates)\n",
    "\n",
    "    loss_gan, grads_gan = calculate_gan_loss(gan, period_disc, scale_disc, x, y)\n",
    "    updates, gan_optim = optim1.update(grads_gan, gan_optim, gan)\n",
    "    gan = eqx.apply_updates(gan, updates)\n",
    "\n",
    "    return (\n",
    "        loss_gan,\n",
    "        loss_period,\n",
    "        loss_scale,\n",
    "        gan,\n",
    "        period_disc,\n",
    "        scale_disc,\n",
    "        gan_optim,\n",
    "        period_optim,\n",
    "        scale_optim,\n",
    "        result,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "I won't repeat myself much, the procedure is the same as the one in [Implementing a VQVAE in JAX for fun üòé](https://tugdual.fr/Audio-VQVAE-for-JAX/). We'll be using LJSpeech [@ljspeech17] just like in that article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "::: {.column-margin}\n",
    "![Feel free to take a break as the download happens, you deserve it !](assets/cat.png)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugdual/miniconda3/envs/jaxtts/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-07 18:42:22--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "Resolving data.keithito.com (data.keithito.com)... 24.199.73.137\n",
      "Connecting to data.keithito.com (data.keithito.com)|24.199.73.137|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2748572632 (2,6G) [text/plain]\n",
      "Saving to: ‚ÄòLJSpeech-1.1.tar.bz2‚Äô\n",
      "\n",
      "LJSpeech-1.1.tar.bz   0%[                    ]   2,44M   463KB/s    eta 1h 51m ^C\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvjf ./LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy\n",
    "\n",
    "sample_rate = 22050\n",
    "\n",
    "\n",
    "def dvae_wav_to_mel(\n",
    "    wav, mel_norms_file=\"./mel_stats.pth\", mel_norms=None, device=torch.device(\"cpu\")\n",
    "):\n",
    "    mel_stft = torchaudio.transforms.MelSpectrogram(\n",
    "        n_fft=1024,\n",
    "        hop_length=256,\n",
    "        win_length=1024,\n",
    "        power=2,\n",
    "        normalized=False,\n",
    "        sample_rate=22050,\n",
    "        f_min=0,\n",
    "        f_max=8000,\n",
    "        n_mels=80,\n",
    "        norm=\"slaney\",\n",
    "    ).to(device)\n",
    "    wav = wav.to(device)\n",
    "    mel = mel_stft(wav)\n",
    "    mel = torch.log(torch.clamp(mel, min=1e-5))\n",
    "    if mel_norms is None:\n",
    "        mel_norms = torch.load(mel_norms_file, map_location=device)\n",
    "    mel = mel / mel_norms.unsqueeze(0).unsqueeze(-1)\n",
    "    return mel\n",
    "\n",
    "\n",
    "dataset_dest_path = \"./dataset/mels\"\n",
    "\n",
    "os.makedirs(dataset_dest_path, exist_ok=True)\n",
    "files = list(Path(\"./LJSpeech-1.1\").rglob(\"*.wav\"))\n",
    "\n",
    "\n",
    "def boop():\n",
    "    for file in tqdm(files):\n",
    "        y, sr = librosa.load(file)\n",
    "        if sr != sample_rate:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=sample_rate)\n",
    "        y = torch.from_numpy(y)\n",
    "        mel = dvae_wav_to_mel(y)\n",
    "\n",
    "        data = mel.cpu().numpy()\n",
    "        save_path = Path(dataset_dest_path, f\"{file.stem}.npy\")\n",
    "        numpy.save(save_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hdfw6x594jbbkfl6hzwf8cxw0000gn/T/ipykernel_42474/1578592260.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mel_norms = torch.load(mel_norms_file, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 173])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "wav = torch.ones((300 * 256) - 1024)\n",
    "wav = torch.ones(22050 * 2)\n",
    "mel = dvae_wav_to_mel(wav, mel_norms_file=\"../VQVAE/mel_stats.pth\")\n",
    "mel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a folder full of mel spectrograms ready to be fed into our model, we can start the training ! Below, we do multiple things:\n",
    "\n",
    "Initialize the model, the optimizer that will nugde it based on the losses our function returns, logging with tensorboard and saving the model every epoch.\n",
    "\n",
    "## Actually training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiScaleDiscriminator(\n",
      "  discriminators=[\n",
      "    DiscriminatorS(\n",
      "      layers=[\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[128,1,15],\n",
      "          bias=f32[128,1],\n",
      "          in_channels=1,\n",
      "          out_channels=128,\n",
      "          kernel_size=(15,),\n",
      "          stride=(1,),\n",
      "          padding=((7, 7),),\n",
      "          dilation=(1,),\n",
      "          groups=1,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[128,32,41],\n",
      "          bias=f32[128,1],\n",
      "          in_channels=128,\n",
      "          out_channels=128,\n",
      "          kernel_size=(41,),\n",
      "          stride=(2,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=4,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[256,8,41],\n",
      "          bias=f32[256,1],\n",
      "          in_channels=128,\n",
      "          out_channels=256,\n",
      "          kernel_size=(41,),\n",
      "          stride=(2,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[512,16,41],\n",
      "          bias=f32[512,1],\n",
      "          in_channels=256,\n",
      "          out_channels=512,\n",
      "          kernel_size=(41,),\n",
      "          stride=(4,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,32,41],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=512,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(41,),\n",
      "          stride=(4,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,64,41],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=1024,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(41,),\n",
      "          stride=(1,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,1024,5],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=1024,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(5,),\n",
      "          stride=(1,),\n",
      "          padding=((2, 2),),\n",
      "          dilation=(1,),\n",
      "          groups=1,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        )\n",
      "      ],\n",
      "      conv_post=Conv1d(\n",
      "        num_spatial_dims=1,\n",
      "        weight=f32[1,1024,3],\n",
      "        bias=f32[1,1],\n",
      "        in_channels=1024,\n",
      "        out_channels=1,\n",
      "        kernel_size=(3,),\n",
      "        stride=(1,),\n",
      "        padding=((1, 1),),\n",
      "        dilation=(1,),\n",
      "        groups=1,\n",
      "        use_bias=True,\n",
      "        padding_mode='ZEROS'\n",
      "      )\n",
      "    ),\n",
      "    DiscriminatorS(\n",
      "      layers=[\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[128,1,15],\n",
      "          bias=f32[128,1],\n",
      "          in_channels=1,\n",
      "          out_channels=128,\n",
      "          kernel_size=(15,),\n",
      "          stride=(1,),\n",
      "          padding=((7, 7),),\n",
      "          dilation=(1,),\n",
      "          groups=1,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[128,32,41],\n",
      "          bias=f32[128,1],\n",
      "          in_channels=128,\n",
      "          out_channels=128,\n",
      "          kernel_size=(41,),\n",
      "          stride=(2,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=4,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[256,8,41],\n",
      "          bias=f32[256,1],\n",
      "          in_channels=128,\n",
      "          out_channels=256,\n",
      "          kernel_size=(41,),\n",
      "          stride=(2,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[512,16,41],\n",
      "          bias=f32[512,1],\n",
      "          in_channels=256,\n",
      "          out_channels=512,\n",
      "          kernel_size=(41,),\n",
      "          stride=(4,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,32,41],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=512,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(41,),\n",
      "          stride=(4,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,64,41],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=1024,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(41,),\n",
      "          stride=(1,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,1024,5],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=1024,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(5,),\n",
      "          stride=(1,),\n",
      "          padding=((2, 2),),\n",
      "          dilation=(1,),\n",
      "          groups=1,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        )\n",
      "      ],\n",
      "      conv_post=Conv1d(\n",
      "        num_spatial_dims=1,\n",
      "        weight=f32[1,1024,3],\n",
      "        bias=f32[1,1],\n",
      "        in_channels=1024,\n",
      "        out_channels=1,\n",
      "        kernel_size=(3,),\n",
      "        stride=(1,),\n",
      "        padding=((1, 1),),\n",
      "        dilation=(1,),\n",
      "        groups=1,\n",
      "        use_bias=True,\n",
      "        padding_mode='ZEROS'\n",
      "      )\n",
      "    ),\n",
      "    DiscriminatorS(\n",
      "      layers=[\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[128,1,15],\n",
      "          bias=f32[128,1],\n",
      "          in_channels=1,\n",
      "          out_channels=128,\n",
      "          kernel_size=(15,),\n",
      "          stride=(1,),\n",
      "          padding=((7, 7),),\n",
      "          dilation=(1,),\n",
      "          groups=1,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[128,32,41],\n",
      "          bias=f32[128,1],\n",
      "          in_channels=128,\n",
      "          out_channels=128,\n",
      "          kernel_size=(41,),\n",
      "          stride=(2,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=4,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[256,8,41],\n",
      "          bias=f32[256,1],\n",
      "          in_channels=128,\n",
      "          out_channels=256,\n",
      "          kernel_size=(41,),\n",
      "          stride=(2,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[512,16,41],\n",
      "          bias=f32[512,1],\n",
      "          in_channels=256,\n",
      "          out_channels=512,\n",
      "          kernel_size=(41,),\n",
      "          stride=(4,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,32,41],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=512,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(41,),\n",
      "          stride=(4,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,64,41],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=1024,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(41,),\n",
      "          stride=(1,),\n",
      "          padding=((20, 20),),\n",
      "          dilation=(1,),\n",
      "          groups=16,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        Conv1d(\n",
      "          num_spatial_dims=1,\n",
      "          weight=f32[1024,1024,5],\n",
      "          bias=f32[1024,1],\n",
      "          in_channels=1024,\n",
      "          out_channels=1024,\n",
      "          kernel_size=(5,),\n",
      "          stride=(1,),\n",
      "          padding=((2, 2),),\n",
      "          dilation=(1,),\n",
      "          groups=1,\n",
      "          use_bias=True,\n",
      "          padding_mode='ZEROS'\n",
      "        )\n",
      "      ],\n",
      "      conv_post=Conv1d(\n",
      "        num_spatial_dims=1,\n",
      "        weight=f32[1,1024,3],\n",
      "        bias=f32[1,1],\n",
      "        in_channels=1024,\n",
      "        out_channels=1,\n",
      "        kernel_size=(3,),\n",
      "        stride=(1,),\n",
      "        padding=((1, 1),),\n",
      "        dilation=(1,),\n",
      "        groups=1,\n",
      "        use_bias=True,\n",
      "        padding_mode='ZEROS'\n",
      "      )\n",
      "    )\n",
      "  ],\n",
      "  meanpool=AvgPool1d(\n",
      "    init=0,\n",
      "    operation=<function add>,\n",
      "    num_spatial_dims=1,\n",
      "    kernel_size=(4,),\n",
      "    stride=(2,),\n",
      "    padding=((2, 2),),\n",
      "    use_ceil=False\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hdfw6x594jbbkfl6hzwf8cxw0000gn/T/ipykernel_42474/2833802545.py:81: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 44288)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sub got incompatible shapes for broadcasting: (32, 1, 44288), (32, 1, 44100).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m mels, wavs \u001b[38;5;241m=\u001b[39m get_batch(batch_indices)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Terrifying\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m gan_loss, period_loss, scale_loss, generator, period_disc, scale_disc, gan_optim, period_optim, scale_optim, output \u001b[38;5;241m=\u001b[39m make_step(generator, period_disc, scale_disc, mels, wavs, gan_optim, period_optim, scale_optim, optim1, optim2, optim3)\n\u001b[1;32m     95\u001b[0m step \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(mel_file_paths) \u001b[38;5;241m+\u001b[39m i\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Log codebook updates to TensorBoard\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[122], line 61\u001b[0m, in \u001b[0;36mmake_step\u001b[0;34m(gan, period_disc, scale_disc, x, y, gan_optim, period_optim, scale_optim, optim1, optim2, optim3)\u001b[0m\n\u001b[1;32m     58\u001b[0m updates, period_optim \u001b[38;5;241m=\u001b[39m optim3\u001b[38;5;241m.\u001b[39mupdate(grads_period, period_optim, period_disc)\n\u001b[1;32m     59\u001b[0m period_disc \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(period_disc, updates)\n\u001b[0;32m---> 61\u001b[0m loss_gan, grads_gan \u001b[38;5;241m=\u001b[39m calculate_gan_loss(gan, period_disc, scale_disc, x, y)\n\u001b[1;32m     62\u001b[0m updates, gan_optim \u001b[38;5;241m=\u001b[39m optim1\u001b[38;5;241m.\u001b[39mupdate(grads_gan, gan_optim, gan)\n\u001b[1;32m     63\u001b[0m gan \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(gan, updates)\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[122], line 9\u001b[0m, in \u001b[0;36mcalculate_gan_loss\u001b[0;34m(gan, period, scale, x, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m fake_scale, _ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(scale)(gan_result)\n\u001b[1;32m      7\u001b[0m fake_period, _ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(period)(gan_result)\n\u001b[0;32m----> 9\u001b[0m l1_loss \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mmean(jax\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mabs(gan_result \u001b[38;5;241m-\u001b[39m y))  \u001b[38;5;66;03m# L1 loss\u001b[39;00m\n\u001b[1;32m     10\u001b[0m G_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fake \u001b[38;5;129;01min\u001b[39;00m fake_period:\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1050\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1050\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maval, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:573\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    571\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 573\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/numpy/ufunc_api.py:177\u001b[0m, in \u001b[0;36mufunc.__call__\u001b[0;34m(self, out, where, *args)\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__static_props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_vectorized\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call(\u001b[38;5;241m*\u001b[39margs)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/numpy/ufuncs.py:1463\u001b[0m, in \u001b[0;36m_subtract\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jit, inline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subtract\u001b[39m(x: ArrayLike, y: ArrayLike, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Subtract two arrays element-wise.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \n\u001b[1;32m   1440\u001b[0m \u001b[38;5;124;03m  JAX implementation of :obj:`numpy.subtract`. This is a universal function,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    Array([-10,  -9,  -8,  -7], dtype=int32)\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1463\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;241m*\u001b[39mpromote_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtract\u001b[39m\u001b[38;5;124m\"\u001b[39m, x, y))\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/jax/_src/lax/lax.py:2072\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   2070\u001b[0m       result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2071\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2072\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2073\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: sub got incompatible shapes for broadcasting: (32, 1, 44288), (32, 1, 44100)."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import chex\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tensorboardX import SummaryWriter\n",
    "from optax._src import utils\n",
    "\n",
    "\n",
    "dataset_path = \"../VQVAE/dataset/mels\"\n",
    "\n",
    "mel_file_paths = os.listdir(dataset_path)\n",
    "files = list(Path(\"../VQVAE/dataset/LJSpeech-1.1\").rglob(\"*.wav\"))\n",
    "\n",
    "def truncate_and_pad_mel(audio: jax.Array, width: int = 173): # This corresponds to around 2 seconds of audio, based on hop length, audio sample rate and window size.\n",
    "    audio_length = audio.shape[1]\n",
    "    \n",
    "    target_length = int(width)\n",
    "    if audio_length > target_length:\n",
    "        audio = audio[:, :target_length]\n",
    "    else:\n",
    "        audio = jnp.pad(audio, ((0, 0), (0, max(0, target_length - audio_length))))\n",
    "    return audio\n",
    "\n",
    "def truncate_and_pad_wav(audio, width: int = 22050*2): # This corresponds to around 2 seconds of audio, based on hop length, audio sample rate and window size.\n",
    "    audio_length = audio.shape[0]\n",
    "    \n",
    "    target_length = int(width)\n",
    "    if audio_length > target_length:\n",
    "        audio = audio[:target_length]\n",
    "    else:\n",
    "        audio = jnp.pad(audio, ((0, max(0, target_length - audio_length))))\n",
    "    return audio\n",
    "\n",
    "def get_batch(idx: list):\n",
    "    batch_mel = []\n",
    "    batch_wav = []\n",
    "\n",
    "    for id in idx:\n",
    "        array = jnp.load(os.path.join(dataset_path, mel_file_paths[id]))[0]\n",
    "        padded = truncate_and_pad_mel(array)\n",
    "        batch_mel.append(padded)\n",
    "        \n",
    "        array, _ = librosa.load(files[id])\n",
    "        padded_array = truncate_and_pad_wav(array)\n",
    "        padded_array = jnp.expand_dims(padded_array, 0)\n",
    "        batch_wav.append(padded_array) # 2 Seconds\n",
    "\n",
    "    return jnp.array(batch_mel), jnp.array(batch_wav)\n",
    "        \n",
    "key = jax.random.PRNGKey(69)\n",
    "\n",
    "key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "generator = Generator(channels_in=80, channels_out=1, key=key1)\n",
    "scale_disc = MultiScaleDiscriminator(key=key2)\n",
    "period_disc = MultiPeriodDiscriminator(key=key3)\n",
    "\n",
    "optim1 = optax.adam(2e-4, b1=0.8, b2=0.99)\n",
    "\n",
    "# Assuming 'generator' is your input\n",
    "gan_optim = optim1.init(generator) # type: ignore\n",
    "\n",
    "optim2 = optax.adam(1e-4)\n",
    "print(scale_disc)\n",
    "scale_optim = optim2.init(scale_disc) # type: ignore\n",
    "\n",
    "optim3 = optax.adam(1e-4)\n",
    "period_optim = optim3.init(period_disc) # type: ignore\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.show()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    key, grab = jax.random.split(key, 2)\n",
    "    perm = jax.random.permutation(grab, len(mel_file_paths))\n",
    "    eqx.tree_serialise_leaves(f\"checkpoints/{epoch}.eqx\", generator)\n",
    "\n",
    "    for i in range(0, len(mel_file_paths), batch_size):\n",
    "        batch_indices = perm[i: i + batch_size]\n",
    "        mels, wavs = get_batch(batch_indices)\n",
    "\n",
    "        # Terrifying\n",
    "        gan_loss, period_loss, scale_loss, generator, period_disc, scale_disc, gan_optim, period_optim, scale_optim, output = make_step(generator, period_disc, scale_disc, mels, wavs, gan_optim, period_optim, scale_optim, optim1, optim2, optim3)\n",
    "\n",
    "        step = epoch * len(mel_file_paths) + i\n",
    "        # Log codebook updates to TensorBoard\n",
    "        writer.add_scalar('Loss/Generator', gan_loss, step)\n",
    "        writer.add_scalar('Loss/Multi Period', period_loss, step)\n",
    "        writer.add_scalar('Loss/Multi Scale', scale_loss, step)\n",
    "        \n",
    "        if (i // batch_size) % 20 == 0:\n",
    "            ax.clear()\n",
    "            ax.plot(wavs[0], color=\"red\", aspect='auto', origin='lower', label=\"Input\")\n",
    "            ax.plot(output[0], color=\"blue\", aspect='auto', origin='lower', label=\"Output\")\n",
    "            display(fig)\n",
    "            ax.legend()\n",
    "            display(fig)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "    # plt.imshow(y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little bit of patience, we can see the output image start to resemble more and more the input one ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result after just 10 minutes of training on a NVIDIA L40](assets/result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tensorboard we can also see that the codewords are progressively all used by the same amount during training. It's beautiful ü•∞\n",
    "\n",
    "![Codebooks slowly all being used uniformily.](<assets/uniform.png>)\n",
    "\n",
    "This concludes this chapter, if you have any questions or remarks feel free to reach out to me ! @sxyBoi on Telegram üòÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "nocite: |\n",
    "  @*\n",
    "---\n",
    "\n",
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
